{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d2adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a04ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213923b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create network\n",
    "class block(nn.Module):\n",
    "    def __init__(self,planes):\n",
    "        super(block, self).__init__()\n",
    "        self.fc1 = nn.Linear(planes,planes)\n",
    "        self.fc2 = nn.Linear(planes,planes)\n",
    "        self.fc3 = nn.Linear(planes,planes)\n",
    "        self.fc4 = nn.Linear(planes,planes)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,a,b,c,d,x0,x1=None,x2=None,x3=None):\n",
    "\n",
    "        x_1 = self.fc1(x0)\n",
    "        x_2 = self.fc2(x1)\n",
    "        x_3 = self.fc3(x2)\n",
    "        x_4 = self.fc4(x3)\n",
    "        x5= a*x_1 + b*x_2 + c*x_3+ d*x_4\n",
    "        x5 = self.relu(x5)\n",
    "        return x_2,x_3,x_4,x5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,block,planes):\n",
    "        super(Net,self).__init__()\n",
    "        self.a = nn.Parameter(torch.Tensor(1).uniform_(0.5, 1),requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.Tensor(1).uniform_(-1, 1),requires_grad=True)\n",
    "        self.c = nn.Parameter(torch.Tensor(1).uniform_(0,0.5),requires_grad=True)\n",
    "        self.block1 = block(planes)\n",
    "        self.block2 = block(planes)\n",
    "        self.block3 = block(planes)\n",
    "        self.block4 = block(planes)\n",
    "        self.block5 = block(planes)\n",
    "        self.block6 = block(planes)\n",
    " \n",
    "        self.fc = nn.Linear(planes,4)\n",
    "    def forward(self,x):\n",
    "        x_1,x_2,x_3,out = self.block1(1+self.c,-2*self.c,self.c,self.b,x)\n",
    "        x_1,x_2,x_3,out = self.block2(1+self.c,-2*self.c,self.c,self.b,x_1,x_2,x_3,out)\n",
    "        x_1,x_2,x_3,out = self.block3(1+self.c,-2*self.c,self.c,self.b,x_1,x_2,x_3,out)\n",
    "        x_1,x_2,x_3,out = self.block4(1+self.c,-2*self.c,self.c,self.b,x_1,x_2,x_3,out)\n",
    "        x_1,x_2,x_3,out = self.block5(1+self.c,-2*self.c,self.c,self.b,x_1,x_2,x_3,out)\n",
    "        _,_,_,out = self.block6(1+self.c,-2*self.c,self.c,self.b,x_1,x_2,x_3,out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e10b0af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d25c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "planes = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "time_step= 4\n",
    "train_num = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f162334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., -1.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#load data\n",
    "def sample(time_step,train_num): \n",
    "    sample_num = 20000\n",
    "    t=np.linspace(0,2*np.pi, sample_num).reshape(sample_num,1)\n",
    "    Sint=np.sin(t)\n",
    "    Cost=np.cos(t)\n",
    "    X = np.hstack((Sint,Cost))\n",
    "    X = np.hstack((X,-Cost))\n",
    "    X = np.hstack((X,Sint))\n",
    "    Y_t = np.hstack((Sint,-Cost))\n",
    "    Y_t = np.hstack((Y_t,Cost))\n",
    "    Y_t = np.hstack((Y_t,Sint))\n",
    "    xTrainDataset = X[0:train_num]\n",
    "    yTrainDataset = Y_t[0:train_num]\n",
    "    xTrain = []\n",
    "    yTrain = []\n",
    "    for i in range(time_step,  train_num):\n",
    "        data = xTrainDataset[i-time_step]\n",
    "        for j in range(1,time_step):\n",
    "            data = np.hstack((data,xTrainDataset[i-time_step+j]))\n",
    "        xTrain.append(data)\n",
    "    for i in range(time_step, train_num):\n",
    "        yTrain.append(yTrainDataset[i])\n",
    "    return xTrain,yTrain\n",
    "\n",
    "x,y=sample(time_step,train_num)\n",
    "\n",
    "tensor_x = torch.Tensor(x) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(y)\n",
    "train_dataset = data.TensorDataset(tensor_x,tensor_y) # create  datset\n",
    "train_loader = data.DataLoader(train_dataset) # create  dataloader\n",
    "x[0][0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73d013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize network\n",
    "model = Net(block,planes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba41601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "critirion = nn.L1Loss()\n",
    "optimizer = optim.Adam(params=model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6af2513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1236], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.2472], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1236], device='cuda:0', requires_grad=True)\n",
      "epoch: 0 loss: 0.00176498\n",
      "tensor([1.1675], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.3349], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1675], device='cuda:0', requires_grad=True)\n",
      "epoch: 1 loss: 0.00176379\n",
      "tensor([1.1962], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.3924], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1962], device='cuda:0', requires_grad=True)\n",
      "epoch: 2 loss: 0.00240406\n",
      "tensor([1.1952], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.3903], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1952], device='cuda:0', requires_grad=True)\n",
      "epoch: 3 loss: 0.00167682\n",
      "tensor([1.1121], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.2242], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1121], device='cuda:0', requires_grad=True)\n",
      "epoch: 4 loss: 0.00225731\n",
      "tensor([1.1010], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.2020], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1010], device='cuda:0', requires_grad=True)\n",
      "epoch: 5 loss: 0.00195184\n",
      "tensor([1.1406], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.2811], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1406], device='cuda:0', requires_grad=True)\n",
      "epoch: 6 loss: 0.00172820\n",
      "tensor([1.0931], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.1863], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.0931], device='cuda:0', requires_grad=True)\n",
      "epoch: 7 loss: 0.00110108\n",
      "tensor([1.1155], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.2310], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.1155], device='cuda:0', requires_grad=True)\n",
      "epoch: 8 loss: 0.00245228\n",
      "tensor([1.0879], device='cuda:0', grad_fn=<AddBackward0>) tensor([-0.1758], device='cuda:0', grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor([0.0879], device='cuda:0', requires_grad=True)\n",
      "epoch: 9 loss: 0.00013335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(1+model.c,-2*model.c,model.c)\n",
    "    for tdata,target in train_loader:\n",
    "        tdata = tdata.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "        \n",
    "        scores = model(tdata)\n",
    "        loss = critirion(scores,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'epoch: {epoch} loss: {loss.item():10.8f}')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06397382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7410d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135b076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('pytorch_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "112afcdae7d1037ee1f4274e23bc7ac65922657208ceff315e859399619f393c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
